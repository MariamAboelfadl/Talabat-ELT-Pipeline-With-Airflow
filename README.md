# Data Pipeline with Airflow, Postgres, GCS, and BigQuery

## ðŸ“Œ Overview
This project demonstrates a **modern data pipeline** using:
- **Postgres** â†’ Source database with sample data.
- **Google Cloud Storage (GCS)** â†’ Staging layer.
- **BigQuery** â†’ Data warehouse (with Dimensions & Facts).
- **Airflow** â†’ Orchestrator for all pipeline tasks.

The pipeline:
1. Creates tables in Postgres and inserts mock data.
2. Extracts data from Postgres â†’ uploads to GCS.
3. Loads data from GCS â†’ BigQuery (raw tables).
4. Transforms data â†’ inserts into **Dimensions** and **Facts** tables in BigQuery.
5. A master DAG triggers all the above DAGs in sequence.

